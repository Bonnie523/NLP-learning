## 【任务3 - 特征提取】时长：2天  
***  
### 1.基本文本处理技能        
#### 1.1 分词的概念   
中文分词(Chinese Word Segmentation) 指的是将一个汉字序列切分成一个一个单独的词。分词就是将连续的字序列按照一定的规范重新组合成词序列的过程。    
由于计算机只认识数字符号，对于英文、汉字这类“高级语言”计算机还没考过1级证书。而对于一句话（sentence）组成的基本单位就是字和词。想要对一句话进行编码成计算机能认识的话，则第一步就需要讲一句话按照语义切分成字和词，
然后单独处理这些字和词就方便得多了。这个便是分词。

分词算法设计中的几个基本原则：  
1、颗粒度越大越好：用于进行语义分析的文本分词，要求分词结果的颗粒度越大，即单词的字数越多，所能表示的含义越确切。    
2、切分结果中非词典词越少越好。“技术 和 服务”有0个非词典词，因此选用后者。   
3、总体词数越少越好，在相同字数的情况下，总词数越少，说明语义单元越少，那么相对的单个语义单元的权重会越大，因此准确性会越高。    
***
下面详细说说正向最大匹配法、逆向最大匹配法和双向最大匹配法具体是如何进行的：    
先说说什么是最大匹配法：最大匹配是指以词典为依据，取词典中最长单词为第一次 取字数量的扫描串，在词典中进行扫描。    
例如：词典中最长词为“中华人民共和国”共7个汉字，则最大匹配起始字数为7个汉字。然后逐字递减，在对应的词典中进行查找。    

a、正向最大匹配法，是一种分治+贪婪的思想，并不一次处理全部串，而是分别处理预先设立长度的每一段，在每一段中求取最长的并且出现在字典里面的词。  
* 例如：abcdef，预先设立的最大长度为3。所以，先从串的开始截取长度为三的子串，即abc，如果abc出现在字典中，那么abc将作为分词结果，
接着以相同方式处理def；   
* 如果abc没出现在字典里面，则从右边减少一个字符，再次匹配字典，即ab匹配，减少的字符将加入之前未选择的字符集里面作下一次匹配，
这里是cdef，如果一个串没匹配到长度大于1的字典词，则返回最左边的字符作为该串的分词结果，也就是ab如果没有匹配到，无论a是否在字典中，都将作为分词结果。

b、有了正向最大分词，逆向就很好理解了，正向是从前向后选取最大长度的串，然后从选取串的尾部向前匹配字典词，删除右边的字符。
逆向最大便是从后向前选取最大长度的串，从选取串开始向后匹配字典词，而删减的也便是左边的字符。    

c、双向最大匹配法：   
正向最大匹配法和逆向最大匹配法，都有其局限性因此有人又提出了双向最大匹配法，双向最大匹配法。
即，两种算法都切一遍，然后根据大颗粒度词越多越好，非词典词和单字词越少越好的原则，选取其中一种分词结果输出。  
如：“我们在野生动物园玩”  
正向最大匹配法，最终切分结果为：“我们/在野/生动/物/园/玩”，其中，两-字词有3个，单字字典词有2个，非词典词为1。   
逆向最大匹配法，最终切分结果为：“我们/在/野生动物园/玩”，其中，五字词有1个，两字词有1个，单字字典词为2，非词典词为0。   
非字典词：正向(1)>逆向(0)（越少越好）    
单字字典词：正向(2)=逆向(2)（越少越好）   
总词数：正向(6)>逆向(4)（越少越好）   
因此最终输出为逆向结果。  

#### 1.2 词、字符频率统计；   
（可以使用Python中的collections.Counter模块，也可以自己寻找其他好用的库）

