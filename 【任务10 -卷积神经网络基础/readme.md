***
1. 卷积运算的定义、动机（稀疏权重、参数共享、等变表示）。一维卷积运算和二维卷积运算。  
2. 反卷积(tf.nn.conv2d_transpose)  
3. 池化运算的定义、种类（最大池化、平均池化等）、动机。   
4. Text-CNN的原理。   
5. 利用Text-CNN模型来进行文本分类。   

参考资料    
卷积有多少种？一文读懂深度学习中的各种卷积：卷积有多少种？一文读懂深度学习中的各种卷积 - 知乎(https://zhuanlan.zhihu.com/p/57575810)   
****   
## 1. 卷积的定义   
![卷积](./images/卷积.png)    
[这篇文章通过举例来具体说明了这两个公式得到实际用途](https://www.cnblogs.com/sevenyuan/p/7810755.html)   
![一通道卷积过程](./images/一通道卷积过程.png)   
![三通道卷积描述](./images/三通道卷积描述.png)   
![三通道卷积过程](./images/三通道卷积过程.png)   
[卷积神经网络之卷积计算、作用与思想 ](https://www.cnblogs.com/shine-lee/p/9932226.html)   
**理解卷积**
这里提供两个理解卷积的角度：
&emsp;&emsp;从函数（或者说映射、变换）的角度理解。 卷积过程是在图像每个位置进行线性变换映射成新值的过程，将卷积核看成权重，若拉成向量记为w
，图像对应位置的像素拉成向量记为x，则该位置卷积结果为y=w′x+b，即向量内积+偏置，将x变换为y。从这个角度看，**多层卷积是在进行逐层映射，整体构成一个复杂函数，训练过程是在学习每个局部映射所需的权重，训练过程可以看成是函数拟合的过程。**     

&emsp;&emsp;从模版匹配的角度理解。 前面我们已经知道，卷积与相关在计算上可以等价，相关运算常用模板匹配，即认为**卷积核定义了某种模式，卷积（相关）运算是在计算每个位置与该模式的相似程度，或者说每个位置具有该模式的分量有多少，当前位置与该模式越像，响应越强。**   
#### 动机  
&emsp;&emsp;卷积运算通过三个重要的思想来帮助改进机器学习系统：**稀疏交互**(sparse interactions)、**参数共享**(parameter sharing)、**等变表示**(equivariant representations)。   
* 稀疏交互：核的大小远小于输入。相对于全连接，一个输入项只影响较少神经元，大大减少运算量。  
* 参数共享：也叫绑定权重，每个核的权重不变，遍历整个输入。使我们只需要少量参数，   
* 等变表示：卷积网络具有平移等变的性质。  
![动机1](./images/动机1.png)     
![动机2](./images/动机2.png)     
检测鸟嘴的位置，可以用一个fliter(固定的模式)来检测图中到底有没有鸟嘴   
![池化1](./images/池化1.png)   
更改图片的大小，上图中变为十分之一（通过去掉奇数列和偶数行），不会影响对图像的影响，同时可以扩大神经元的视野范围   
